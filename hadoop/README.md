Table of contents
* [Introduction](#Introduction)
* [Hadoop Cluster](#Hadoop-Cluster)
* [Hive Project](#Hadoop-Project)
* [Improvements](#Improvements)

# Introduction
- In this project, Jarvis data analytics team wants to move from SAP and R to the Hadoop ecosystem for processing big data. Used Apache Hadoop, HDFS, YARN, Hive, Zeppelin to process `World Developement Indicators (WDI)` and generate meaningful insights
    - Provisioned Hadoop Cluster on GCP (Google Cloud Platform)
    - Solved business problems using Apache Hive and Zeppelin Notebook.

# Hadoop Cluster
- Diagram <br>
    ![diagram]('asset/hadoop_cluster.png')
  - 1 master and 2 workers nodes
  - HDFS, YARN, Zeppelin, Hive (hive Server, hive metastore, RDBMS), etc.
- Big data tools you evaluated (e.g. MapReduce, YARN, HDFS, Hive, Zeppelin, etc..)
- hardware specifications

# Hive Project
- Discuss how you optimized Hive queries? (e.g. partitions, columnar, etc..)
- Post your Zeppelin Notebook screenshot here
	- Make sure your Notebook is nice and clean as hiring managers will visit your project
	- use `Full Page Screen Capture` chrome extension to capture a webpage as a picture

# Improvements
- at least three improvements